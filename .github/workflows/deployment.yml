name: Deployment

env:
  GCP_PROJECT_ID: "fast-ai-exploration"
  GKE_CLUSTER: "tfs-cluster"
  GKE_REGION: "us-central1"
  IMAGE: "gcr.io/fast-ai-exploration/tfs-k8s"
  GKE_DEPLOYMENT: "tfs-server"
  
on:
  release:
    types: [published]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Download the latest model release
        uses: robinraju/release-downloader@v1.3
        with:
          repository: "deep-diver/ml-deployment-k8s-tfserving"
          latest: true
          fileName: "saved_model.tar.gz"
          
      - name: Extract the SavedModel
        run: |
          tar -xvf saved_model.tar.gz --directory saved_model
    
      - name: Display downloaded release
        run: |
          ls 
    
      - name: Build and push Docker image based on the changes
        run: |
          docker run -d --name serving_base tensorflow/serving

      - name: Set up Kustomize
        run: |
          docker images
    
