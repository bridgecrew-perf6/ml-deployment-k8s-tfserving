# Deploying ML models with TFServing, Docker, and Kubernetes

*By: [Chansung Park](https://github.com/deep-diver) and [Sayak Paul](https://github.com/sayakpaul)*

This project shows how to serve an TensorFlow based image classification model as a
RESTful and gRPC web services with TFServing, Docker, and Kubernetes(k8s). The idea is to first
embed TensorFlow model into the TFServing docker image and then deploy it on a k8s cluster running on [Google Kubernetes
Engine (GKE)](https://cloud.google.com/kubernetes-engine). We do this integration
using [GitHub Actions](https://github.com/features/actions). 

ðŸ‘‹ **Note**: Even though this project uses an image classification its structure and techniques can
be used to serve other models as well.

## Deploying the model as a service with k8s



## Configurations needed beforehand



## Acknowledgements

[ML-GDE program](https://developers.google.com/programs/experts/) for providing GCP credit support.

